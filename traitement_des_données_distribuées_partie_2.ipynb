{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "traitement_des_données_distribués_partie_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiVj4qPtKEQG",
        "colab_type": "text"
      },
      "source": [
        "## Utilisation de pyspark pour un pipeline machine learning : classification du genre sur les discours politiques français\n",
        "\n",
        "### Jing TAN & Melchior PRUGNIAUD \n",
        "###### MS DS || ENSAE\n",
        "\n",
        "Ce sujet réalise des traitements de NLP. Etant donné la complexité de certaines fonctions que nous allons utilisés, il est important de distribué ces computations afin de réduire le temps de travail qui normalement sur une seule machine prendrait des heures. C'est pourquoi utiliser `PySpark` nous semble être une bonne solution.\n",
        "\n",
        "Le but ici est de comprendre l'utilisation de `PySpark` tout en développant un pipeline de machine learning facilement exécutable.\n",
        "\n",
        "Nous avions un problème pour utiliser plusieurs packages sur le cluster de l'ENSAE, c'est pourquoi nous avons au final décider de réaliser l'ensemble des opérations directement sous collab car nous avons plus de maniabilité que sur le cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqZaMu2lYEj9",
        "colab_type": "text"
      },
      "source": [
        "### Partie II : Modèle pré-entraîné et Deep Learning Classification \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9QbsABtKjDt",
        "colab_type": "text"
      },
      "source": [
        "#### Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLeiFReYQ_XE",
        "colab_type": "code",
        "outputId": "7a03ce0b-4495-4d61-b663-86b43739522d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.5.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.5.0\n",
            "  Using cached https://files.pythonhosted.org/packages/75/b0/f50d169c49f5982f8be9e86e285b53e23f91fd7db0d10646c2d1de5c3ad0/spark_nlp-2.5.0-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX2-ncsFYjV0",
        "colab_type": "text"
      },
      "source": [
        "Dans cette partie, nous allons dans un premier temps créer notre baseline avec \n",
        "`pyspark.ml`. Considérons les résultats de la première partie, nous allons d'abord traiter les texte avec différentes procédures de preprocessing, ensuite travailler avec la regression logistique pour la classification. Dans un deuxième temps, nous allons créer un modèle deep learning avec `sparknlp`.\n",
        "\n",
        "> Procédure pour le baseline\n",
        "\n",
        "\n",
        "1.   Vectorizer par exemple, CountVectorizer IDF, HashingTF IDF, etc\n",
        "\n",
        "2.   Word Embedding avec skip-n-gram\n",
        "\n",
        "3.   Classification par la régression logistique\n",
        "\n",
        "> Procédure pour le modèle de deep learning\n",
        "\n",
        "\n",
        "1.   BERT pretrained word embedding\n",
        "\n",
        "2.   Deep Learning classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aXgnQmyUads",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import pyspark\n",
        "import sparknlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF5X-DPaQbWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_eq = pd.read_csv('df_eq.csv')\n",
        "df_eq = df_eq[df_eq.columns[1:]]\n",
        "df_eq.fillna('',inplace=True)\n",
        "def encode(x):\n",
        "  if x == 1:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "df_eq.sexe = df_eq.sexe.apply(encode)\n",
        "\n",
        "#df_pd =  pd.read_csv('medium_df_eq.csv')\n",
        "# Number of rows in the dataframe\n",
        "#print('number of rows in the data frame {}'.format(df_pd.count()))\n",
        "# Number of columns and their labels\n",
        "#print('number of columns in the data frame {}'.format(len(df_pd.columns)))\n",
        "#print('columns: {}'.format(df_pd.columns))\n",
        "\n",
        "#df_pd = df_pd[['Id','Texte', 'sexe']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0t22CZRQbW1",
        "colab_type": "code",
        "outputId": "179cfe92-31de-4c03-8efd-3fce350c56fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = sparknlp.start()\n",
        "df_s = spark.createDataFrame(df_eq)\n",
        "df_s = df_s.select(*['sexe','Texte'])\n",
        "df_s.show(2)\n",
        "\n",
        "df_s.groupBy(\"sexe\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+-----+\n",
            "|sexe|count|\n",
            "+----+-----+\n",
            "|   1| 2500|\n",
            "|   2| 2500|\n",
            "+----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "celqLEF_QbW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_set, val_set, test_set) = df_s.randomSplit([0.8, 0.1, 0.1], seed = 2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jY5UB9aQbW7",
        "colab_type": "code",
        "outputId": "9be8ca2e-fc2d-4fc3-ba71-d6bed04e452c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_set)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W82Gl5AsR_rv",
        "colab_type": "text"
      },
      "source": [
        "## HashingTF + IDF + Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFD7U6q1R-Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9vRgQdaOpcM",
        "colab_type": "text"
      },
      "source": [
        "Qu'est-ce qu'un Pipeline de toute façon? Dans l'apprentissage automatique, il est courant d'exécuter une séquence d'algorithmes pour traiter et apprendre des données.\n",
        "Un pipeline est spécifié comme une séquence d'étapes, et chaque étape est soit un transformateur soit un estimateur. Ces étapes sont exécutées dans l'ordre et le `DataFrame` d'entrée est transformé lors de son passage à chaque étape. Autrement dit, les données sont transmises dans le pipeline ajusté dans l'ordre. La méthode transforme de chaque étape met à jour le jeu de données et le passe à l'étape suivante. Avec l'aide de Pipelines, nous pouvons nous assurer que les données de formation et de test passent par des étapes de traitement des fonctionnalités identiques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG_hRsVDSF7Y",
        "colab_type": "code",
        "outputId": "b6f071ce-063d-41d5-f41b-199cab11f1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Creer une pipeline pour traiter les textes (Tokenizer, vectorizer avec HashTF et IDF)\n",
        "tokenizer = Tokenizer(inputCol=\"Texte\", outputCol=\"words\")\n",
        "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"sexe\", outputCol = \"label\")\n",
        "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
        "\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "train_df = pipelineFit.transform(train_set)\n",
        "val_df = pipelineFit.transform(val_set)\n",
        "train_df.show(5)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+----+--------------------+--------------------+--------------------+-----+\n",
            "|    Id|               Texte|sexe|               words|                  tf|            features|label|\n",
            "+------+--------------------+----+--------------------+--------------------+--------------------+-----+\n",
            "|126905| Pour un nouvel é...|   1|[, pour, un, nouv...|(65536,[187,225,4...|(65536,[187,225,4...|  0.0|\n",
            "|126923|Après avoir arrêt...|   1|[après, avoir, ar...|(65536,[46,104,13...|(65536,[46,104,13...|  0.0|\n",
            "|126994|Monsieur le Prési...|   1|[monsieur, le, pr...|(65536,[131,180,2...|(65536,[131,180,2...|  0.0|\n",
            "|127053|UN MOMENT SOLENNE...|   1|[un, moment, sole...|(65536,[18,33,167...|(65536,[18,33,167...|  0.0|\n",
            "|127078|Vienne, le 28 avr...|   1|[vienne,, le, 28,...|(65536,[75,144,43...|(65536,[75,144,43...|  0.0|\n",
            "+------+--------------------+----+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cuTLa99SPGH",
        "colab_type": "code",
        "outputId": "3943a6d1-a6c7-4cec-a754-1ff484babb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Entrainer le modèle de la Regression logistique \n",
        "lr = LogisticRegression(maxIter=100)\n",
        "lrModel = lr.fit(train_df)\n",
        "predictions = lrModel.transform(val_df)\n",
        "\n",
        "# Evaluer le modèle\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "evaluator.evaluate(predictions)\n",
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7851088908845982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vOnNMPSWWXJ",
        "colab_type": "text"
      },
      "source": [
        "## CountVectorizer + IDF + Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtfgMOLKWXdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6bace10-e48b-456b-c17e-113620b32c47"
      },
      "source": [
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Creer une pipeline pour traiter les texte et faire la regression\n",
        "# (Tokenizer, vectorizer avec CountVectorizer et IDF, regression logistique)\n",
        "tokenizer = Tokenizer(inputCol=\"Texte\", outputCol=\"words\")\n",
        "cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
        "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"sexe\", outputCol = \"label\")\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, lr])\n",
        "# Entrainer le modèle\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "predictions = pipelineFit.transform(val_set)\n",
        "# Evaluer le modèle\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(roc_auc))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.7434\n",
            "ROC-AUC: 0.8102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YA5EMLpWjES",
        "colab_type": "text"
      },
      "source": [
        "## N-gram + CountVect + IDF + Logistic regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWvTyEeCQh0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import NGram, VectorAssembler\n",
        "\n",
        "def build_ngrams_wocs(inputCol=[\"Texte\",\"sexe\"], n=3):\n",
        "  '''\n",
        "  Creer une pipeline pour traiter les texte, faire du skip n gram word embedding et faire la regression logistique\n",
        "  Input :\n",
        "    inputCol : noms de la colonne du texte\n",
        "    n        : nombre de skips\n",
        "  Output:\n",
        "    pipeline : pipeline qui procéde aux traitement du texte et la regression\n",
        "  '''\n",
        "    tokenizer = [Tokenizer(inputCol=\"Texte\", outputCol=\"words\")]\n",
        "    ngrams = [\n",
        "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "\n",
        "    cv = [\n",
        "        CountVectorizer(vocabSize=5460,inputCol=\"{0}_grams\".format(i),\n",
        "            outputCol=\"{0}_tf\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
        "\n",
        "    assembler = [VectorAssembler(\n",
        "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
        "        outputCol=\"features\"\n",
        "    )]\n",
        "    label_stringIdx = [StringIndexer(inputCol = \"sexe\", outputCol = \"label\")]\n",
        "    lr = [LogisticRegression(maxIter=100)]\n",
        "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS8WWToPWvEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73c61503-d005-44b3-ed7f-7f6eebff087d"
      },
      "source": [
        "# Entrainer le modèle\n",
        "trigramwocs_pipelineFit = build_ngrams_wocs().fit(train_set)\n",
        "predictions_wocs = trigramwocs_pipelineFit.transform(val_set)\n",
        "accuracy_wocs = predictions_wocs.filter(predictions_wocs.label == predictions_wocs.prediction).count() / float(val_set.count())\n",
        "roc_auc_wocs = evaluator.evaluate(predictions_wocs)\n",
        "# print accuracy, roc_auc\n",
        "print(\"Accuracy Score: {0:.4f}\".format(accuracy_wocs))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(roc_auc_wocs))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.7753\n",
            "ROC-AUC: 0.8517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twz5yhnNW1qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65729b0b-d15f-4594-a99e-074c2f49a2c3"
      },
      "source": [
        "test_predictions = trigramwocs_pipelineFit.transform(test_set)\n",
        "test_accuracy = test_predictions.filter(test_predictions.label == test_predictions.prediction).count() / float(test_set.count())\n",
        "test_roc_auc = evaluator.evaluate(test_predictions)\n",
        "# print accuracy, roc_auc\n",
        "print(\"Accuracy Score: {0:.4f}\".format(test_accuracy))\n",
        "print(\"ROC-AUC: {0:.4f}\".format(test_roc_auc))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.8049\n",
            "ROC-AUC: 0.8865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FvgvTr-SG3C",
        "colab_type": "text"
      },
      "source": [
        "## SparkNLP pretrained \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxTxHdkFK7u_",
        "colab_type": "text"
      },
      "source": [
        "Dans Spark NLP, tous les annotateurs sont des estimateurs ou des transformateurs comme nous le voyons dans Spark ML. Un estimateur dans Spark ML est un algorithme qui peut être ajusté sur un `DataFrame` pour produire un transformateur. Par exemple, un algorithme d'apprentissage est un estimateur qui s'entraîne sur un `DataFrame` et produit un modèle. Un Transformer est un algorithme qui peut transformer un `DataFrame` en un autre `DataFrame`. Par exemple, un modèle ML est un transformateur qui transforme un `DataFrame` avec des fonctionnalités en un `DataFrame` avec des prédictions. Dans Spark NLP, il existe deux types d'annotateurs: AnnotatorApproach et AnnotatorModel AnnotatorApproach étend les estimateurs à partir de Spark ML, qui sont destinés à être formés via `fit()`, et AnnotatorModel étend les transformateurs qui sont destinés à transformer les trames de données via `transform()`. Certains annotateurs Spark NLP ont un suffixe Model et d'autres non. Le suffixe du modèle est explicitement indiqué lorsque l'annotateur est le résultat d'un processus de formation. Certains annotateurs, tels que `Tokenizer`, sont des transformateurs mais ne contiennent pas le suffixe Model car ils ne sont pas des annotateurs entraînés. Les annotateurs de modèle ont un `pretrained()` sur son objet statique, pour récupérer la version publique pré-formée d'un modèle. Pour faire court, s’il s’entraîne sur un DataFrame et produit un modèle, c’est une AnnotatorApproach; et s'il transforme un `DataFrame` en un autre `DataFrame` via certains modèles, il s'agit d'un AnnotatorModel (par exemple `WordEmbeddingsModel`) et il ne prend pas le suffixe du modèle s'il ne s'appuie pas sur un annotateur pré-formé lors de la transformation d'un `DataFrame` (par exemple `Tokenizer`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHiwuGEJQbWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "spark = sparknlp.start() \n",
        "# sparknlp.start(gpu=True) >> for training on GPU\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iwuTgptQbW_",
        "colab_type": "code",
        "outputId": "1475ad68-1adf-4870-d415-964c136f2d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"Texte\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "# we can also use sentence detector here if we want to train on and get \n",
        "# predictions for each sentence downloading pretrained embeddings\n",
        "use = UniversalSentenceEncoder.pretrained()\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "# the classes/labels/categories are in 'sexe' column\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"sexe\")\\\n",
        "  .setMaxEpochs(10)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "use_clf_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        classsifierdl\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edz16ZpkWHnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_pipelineModel = use_clf_pipeline.fit(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtFo6oWTXq41",
        "colab_type": "code",
        "outputId": "22f57191-f0b5-44d9-966c-b4181601a079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!cd ~/annotator_logs && ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 518 May 14 18:01 ClassifierDLApproach_0d5e46a8ca9d.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkV5WISX8t7",
        "colab_type": "code",
        "outputId": "28e6f402-e1c0-4daf-8592-00e8fba755fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!cat ~/annotator_logs/ClassifierDLApproach_0d5e46a8ca9d.log"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training started - total epochs: 5 - learning rate: 0.005 - batch size: 64 - training examples: 3974\n",
            "Epoch 0/5 - 1.793177918%.2fs - loss: 43.781788 - accuracy: 0.51974124 - batches: 63\n",
            "Epoch 1/5 - 1.139157638%.2fs - loss: 44.482933 - accuracy: 0.62214386 - batches: 63\n",
            "Epoch 2/5 - 1.138320012%.2fs - loss: 45.3547 - accuracy: 0.63012433 - batches: 63\n",
            "Epoch 3/5 - 1.128797706%.2fs - loss: 44.363316 - accuracy: 0.6432291 - batches: 63\n",
            "Epoch 4/5 - 1.132367959%.2fs - loss: 44.203808 - accuracy: 0.64625335 - batches: 63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR47En_1W1iT",
        "colab_type": "code",
        "outputId": "60c76821-0785-4dc7-a80d-fa5a23b833b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = use_pipelineModel.transform(test_set)\n",
        "df = preds.select('sexe','Texte', 'class.result').toPandas()\n",
        "df['result'] = pd.to_numeric(df['result'].apply(lambda x: x[0]))\n",
        "print(classification_report(df.sexe, df.result))\n",
        "print(accuracy_score(df.sexe, df.result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.66      0.44      0.53       225\n",
            "           2       0.63      0.81      0.71       267\n",
            "\n",
            "    accuracy                           0.64       492\n",
            "   macro avg       0.65      0.63      0.62       492\n",
            "weighted avg       0.65      0.64      0.63       492\n",
            "\n",
            "0.6422764227642277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2b_x8KjNlVb",
        "colab_type": "text"
      },
      "source": [
        "Spark NLP fournit une API facile à intégrer avec Spark ML Pipelines et tous les annotateurs et transformateurs Spark NLP peuvent être utilisés dans Spark ML Pipelines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBS33K7rHqWM",
        "colab_type": "code",
        "outputId": "b0ed0bce-c663-461b-cd91-ab041c0f9a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        " .setInputCol(\"Texte\")\\\n",
        " .setOutputCol(\"document\")\n",
        "\n",
        "# split into sentences\n",
        "sentenceDetector = SentenceDetector()\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentences\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        " .setInputCols([\"sentences\"])\\\n",
        " .setOutputCol(\"token\")\n",
        "\n",
        "# removes all dirty characters from text following a regex pattern \n",
        "# and transforms words based on a provided dictionary\n",
        "normalizer = Normalizer()\\\n",
        " .setInputCols([\"token\"])\\\n",
        " .setOutputCol(\"normal\")\n",
        "\n",
        "# exclude from a sequence of strings (e.g. the output of a Tokenizer, Normalizer\n",
        "# , Lemmatizer, and Stemmer) and drops all the stop words from the input sequences.\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        " .setInputCols([\"normal\"])\\\n",
        " .setOutputCol(\"cleanedTokens\")\n",
        "\n",
        "# load pretrained lemmatizer in French\n",
        "# retrieves lemmas out of words with the objective of returning a base dictionary word\n",
        "lemmatizer = LemmatizerModel.pretrained(\"lemma\", lang=\"fr\")\\\n",
        " .setInputCols([\"cleanedTokens\"])\\\n",
        " .setOutputCol(\"lemma\")\n",
        "\n",
        "# load pretrained embeddings multi-lingual\n",
        "word_embeddings = BertEmbeddings\\\n",
        "    .pretrained('bert_multi_cased', 'xx') \\\n",
        "    .setInputCols([\"document\",'lemma'])\\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "    .setPoolingLayer(-2) # default 0\n",
        "\n",
        "sentence_embeddings = SentenceEmbeddings()\\\n",
        " .setInputCols([\"document\",\"embeddings\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\\\n",
        " .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "# deep learning classifier\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"sexe\")\\\n",
        "  .setMaxEpochs(8)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        " document_assembler, \n",
        " sentenceDetector,\n",
        " tokenizer,\n",
        " normalizer,\n",
        " stopwords_cleaner,\n",
        " lemmatizer,\n",
        " word_embeddings,\n",
        " sentence_embeddings,\n",
        " classsifierdl\n",
        " ])\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lemma download started this may take some time.\n",
            "Approximate size to download 2.2 MB\n",
            "[OK!]\n",
            "bert_multi_cased download started this may take some time.\n",
            "Approximate size to download 638.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dppF25WtMSa7",
        "colab_type": "text"
      },
      "source": [
        "Lorsque nous `fit()` sur le pipeline avec le bloc de data frame, sa colonne de texte est introduite dans le transformateur `DocumentAssembler()` dans un premier temps, puis une nouvelle colonne «document» est créée dans Type de document (AnnotatorType). Ce transformateur est fondamentalement le point d'entrée initial de Spark NLP pour toute trame de données Spark. Ensuite, sa colonne de document est introduite dans `SentenceDetector()` (AnnotatorApproach) et le texte est divisé en un tableau de phrases et une nouvelle colonne «phrases» dans Type de document est créée. Ensuite, la colonne «phrases» est introduite dans `Tokenizer()` (AnnotatorModel) et chaque phrase est tokenisée et une nouvelle colonne «token» dans le type Token est créée. Etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CN9rBjvYqTx",
        "colab_type": "code",
        "outputId": "014c6bab-7b23-4d38-9187-acc74a717ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Entrainer le modèle\n",
        "bert_pipelineModel = nlpPipeline.fit(train_set)\n",
        "df = bert_pipelineModel.transform(test_set).select('Texte', 'sexe', 'class.result').toPandas()\n",
        "\n",
        "df['result'] = pd.to_numeric(df['result'].apply(lambda x: x[0]))\n",
        "print(classification_report(df.sexe, df.result))\n",
        "print(accuracy_score(df.sexe, df.result))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       225\n",
            "           2       0.54      1.00      0.70       267\n",
            "\n",
            "    accuracy                           0.54       492\n",
            "   macro avg       0.27      0.50      0.35       492\n",
            "weighted avg       0.29      0.54      0.38       492\n",
            "\n",
            "0.5426829268292683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4jmhPijACgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2991c7dd-13a1-47d8-c3e6-5ef251859e39"
      },
      "source": [
        "bert_pipelineModel.stages"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_b017a8f16175,\n",
              " SentenceDetector_97345b8cc3c5,\n",
              " REGEX_TOKENIZER_21548488e6ee,\n",
              " NORMALIZER_c4f47fb84c4b,\n",
              " StopWordsCleaner_742f67280cc9,\n",
              " LEMMATIZER_21d85c0f00b3,\n",
              " BERT_EMBEDDINGS_a122a99548e9,\n",
              " SentenceEmbeddings_c1fc0aa1159c,\n",
              " ClassifierDLModel_be04f315cbde]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93SdTOdePn3M",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons enregristré notre modèle et le réutiliser plus tard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt_JnHKYDkg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_pipelineModel.stages[-1].write().overwrite().save('myClassifier15052020')\n",
        "classsifierdlmodel = ClassifierDLModel.load('myClassifier15052020')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcq-nVCOPx-y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Les `LightPipeline` sont des pipelines spécifiques à Spark NLP, équivalents à Spark ML Pipeline, mais destinés à traiter de plus petites quantités de données. Ils sont utiles pour travailler avec de petits ensembles de données, déboguer les résultats ou lors de l'exécution d'une formation ou d'une prédiction à partir d'une API qui sert des demandes ponctuelles.\n",
        "\n",
        "Les Spark NLP LightPipelines sont des pipelines Spark ML convertis en une seule machine mais la tâche multithread, devenant plus de 10 fois plus rapide pour de plus petites quantités de données (petite est relative, mais les phrases de 50k sont à peu près un bon maximum). Pour les utiliser, il suffit de brancher un pipeline formé (fitted) puis d'annoter un texte brut. Nous n'avons même pas besoin de convertir le texte d'entrée en DataFrame afin de le nourrir dans un pipeline qui accepte DataFrame comme entrée en premier lieu. Cette fonctionnalité serait très utile lorsqu'il s'agit d'obtenir une prédiction pour quelques lignes de texte à partir d'un modèle ML entrainé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dpHZv8-DGnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2561ce43-4729-4dc5-acdc-b925e259f66a"
      },
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "light_model = LightPipeline(classsifierdlmodel)\n",
        "val_set.select('Texte').take(2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Texte='Mesdames, Messieurs,Je vous ai invité à ce point presse pour vous présenter les Assises nationales du développement durable, que nous organisons, conjointement avec la région Midi-Pyrénées, dont Mme Marie-Françoise Mendez, ici présente, est vice-présidente.Nous nous étions déjà réunis, avec M. le Président Martin Malvy, le 15 janvier dernier, à la signature de la convention entre le MATE et le Conseil Régional Midi-Pyrénées. Aujourd\\'hui, à 10 jours de la tenue de ces Assises, je tenais à vous en rappeler l\\'importance, et à vous en présenter les enjeux.Le sommet mondial du développement durable de Johannesburg aura lieu à la fin du mois d\\'août prochain, c\\'est-à-dire très bientôt.La France et l\\'Europe ont un rôle essentiel à jouer dans ce sommet, d\\'autant, vous l\\'avez vu, que M. le Président Bush menace de ne pas s\\'y rendre lui-même, malgré les exhortations de nombreuses associations.Vous connaissez le contexte électoral particulier dans lequel nous nous trouvons aujourd\\'hui. Il est difficile, dans ces conditions, de se projeter dans l\\'après- mois de mai/juin. Pourtant , c\\'est notre rôle de le faire. Les Assises Nationales du développement durable de Toulouse, qui se tiendront les 11 et 12 mars prochains, seront ainsi l\\'occasion, en France, avant ces échéances électorales internes, d\\'ouvrir un large dialogue sur la préparation du sommet de Johannesburg, et sur le bilan de ce qui a été réalisé dans notre pays depuis la conférence de Rio en 1992.Le concept de développement durable a été popularisé par le rapport \" Brundtland \", rapport de la Commission Mondiale sur l\\'Environnement et le Développement, en 1987. C\\'est dans ce rapport qui a proposé la définition la plus communément admise du développement durable : \" un développement qui réponde aux besoins du présent sans compromettre la capacité des générations futures à répondre aux leurs \" Vous le savez, le Sommet de la Terre, a constitué une étape décisive dans l\\'engagement des pays en faveur du développement durable et dans l\\'expression des finalités et principes fondateurs de ce concept. Elle a mis en valeur l\\'idée selon laquelle \" le monde se localise en même temps qu\\'il se mondialise \". Les espoirs de Rio, vous le savez aussi, n\\'ont pas encore été concrétisés : les modes de production et de consommation ont peu changé, les écarts entre le Nord et le Sud se sont aggravés.Vous connaissez les principes fondateurs du développement durable : la prise en compte, en amont de toute politiques publique et à chaque étape de leur mise en oeuvre, des trois piliers que sont le développement économique, la protection de l\\'environnement, et le bien être social. Cette imbrication suppose de sortir de l\\'idéologie de la croissance du PIB comme seul objectif des politiques de développement. J\\'insiste pour ma part sur le fait que le développement durable envisage la personne humaine dans sa globalité. En ce sens, le souci de l\\'éducation, de la formation tout au long de la vie, de la diversité culturelle et de la protection de la liberté nécessaire à toute création artistique, à toute pensée, font partie du développement durable.Les principes affirmés à Rio irriguent notre action quotidienne, au sein de ce Ministère, mais aussi au sein de toutes les collectivités locales :- le principe d\\'intégration de la protection de l\\'environnement comme partie intégrante du processus de développement ; - le principe de responsabilité et de solidarité internationale ;- le principe de participation et de nouvelle gouvernance ;Les 171 gouvernements présents à Rio ont aussi adopté l\\'Agenda 21 (ou Action 21). Il constitue un plan global d\\'action qui doit être mis en uvre par les gouvernements, les institutions du développement, les organismes des Nations Unies et les secteurs indépendants.Ses 40 chapitres font émerger : - les dimensions économiques et sociales ;- la conservation et la préservation des ressources aux fins de développement ;- la participation de la société civile à l\\'élaboration et la mise en oeuvre d\\'actions s\\'appuyant sur l\\'expression des besoins de la société civile ; - la mise en oeuvre de moyens transversaux à toutes les échelles de territoires. Le chapitre 28 recommande ainsi que les collectivités locales mettent en place un Agenda 21 local, traductionterritorialisée de l\\'Agenda 21.Depuis Rio, une étape majeure a été franchie à Kyoto, en 1997, et Johannesburg sera la prochaine. Les enjeux de Johannesburg sont donc fondamentaux : Le Premier Ministre l\\'a rappelé dans son discours de Lyon, en soulignant notamment la nécessité d\\'une OME, de la ratification du Protocole de Kyoto.Cependant, nous avons quelques inquiétudes car le contexte international n\\'est pas favorable : le programme d\\'action de George Bush pour le changement climatique est inacceptable, la conférence de Carthagène a été décevante, celle de Monterrey ne laisse pas d\\'être inquiétanteDans ce contexte, il importe plus que jamais de se mobiliser pour que le Sommet du Développement Durable soit un succès qui redonne un nouveau souffle au concept, en insistant sur la nécessaire intégration des préoccupations économiques, sociales et environnementales. Il faut mettre les ambitions de Johannesburg à la hauteur de celles de Rio. La globalisation les rend plus que nécessaires en même temps qu\\'elle leur donne un nouveau fondement.L\\'ambition principale est l\\'éradication de la pauvreté, en lien avec l\\'accès aux biens fondamentaux, l\\'eau et l\\'énergie (deux milliards de personnes n\\'ont pas accès à une énergie suffisante), avec le changement de nos modes de production et de consommation.La France travaille à des initiatives sur quatre domaines principaux, l\\'accès à l\\'eau, l\\'accès à l\\'énergie, la protection des ressources naturelles et la diversité biologique. La gouvernance mondiale environnementale reste aussi une de nos ambitions, comme l\\'a rappelé le Premier Ministre à Lyon malgré le relatif échec de la conférence de Carthagène. La mobilisation de tous les acteurs, en France, est fondamentale, d\\'autant plus que le rôle de la France est important par son implication dans le travail de l\\'Union européenne. Le Sommet de Göteborg a en effet adopté une stratégie européenne de développement durable. En mars, le sommet de Barcelone adoptera une stratégie externe de l\\'Union européenne, en vue de Johannesburg, et au delà. Nous en débattrons entre ministres de l\\'environnement le 4 mars, pour ce qui concerne les aspects d\\'environnement et de développement durable. Nos conclusions seront portées à Barcelone. Vous voyez qu\\'il nous reste donc encore quelques leviers pour l\\'action de l\\'Union européenne d\\'ici Johannesburg. Le Premier Ministre a nommé M. Michel Mousel comme président du comité chargé de coordonner les ONG dans la préparation de Johannesburg. Ce comité fonctionne par groupes de travail, dont l\\'un est consacré aux collectivités locales. Le MATE est quant à lui chargé de coordonner la préparation de la stratégie française de développement durable qui sera présentée à Johannesburg, et dont un premier état sera proposé au débat à Toulouse.Cette stratégie est élaborée en concertation avec les associations, les institutions, notamment la Commission française du développement durable, dont je salue ici le rôle, et les collectivités locales.En effet, si les Assises nationales du développement durable de Toulouse ont été organisées en partenariat entre l\\'Etat et le Conseil Régional Midi-Pyrénées, c\\'est bien qu\\'elles sont avant tout celles des collectivités locales. Pourquoi ? Justement parce que la stratégie d\\'action définie à Rio insistait fortement sur la nécessaire implication, participation, des collectivités locales. C\\'était le principe 22 défini à Rio comme celui de la nécessaire participation de tous les acteurs.Les Assises de Toulouse seront donc l\\'occasion de faire le point sur la mise en uvre en France du programme Agenda 21, et notamment de ce chapitre 28 consacré à l\\'implication indispensable des collectivités locales dans les agendas 21. Elles ont pour but d\\'inciter les collectivités locales à s\\'engager dans des démarches d\\'agenda 21, si elles ne l\\'ont pas déjà fait, en s\\'appuyant sur les expériences de celles qui ont ouvert la voie.De nombreuses initiatives ont été prises, qui vous sont présentées dans le dossier de presse, et qui seront débattues à Toulouse.Ces Assises sont ainsi l\\'occasion de partager les expériences réalisées depuis 10 ans par les différentes collectivités, par les institutions, par les associations, par les élus. Je le répète, il s\\'agit de la seule occasion, pour les élus locaux, de s\\'exprimer publiquement sur la mise en uvre de Rio dans leurs collectivités, de faire part de leurs préoccupations pour Johannesburg : c\\'est donc un moment politiquement très important de concertation et d\\'échange, mais aussi de construction politique, puisque les Actes des Assises feront partie du document stratégique présenté par la France au sommet de Johannesburg. 10 ateliers auront donc lieu, autour des deux thèmes majeurs des \" systèmes naturels et humains vulnérables \" et de la \" construction collective des choix de société \". Les deux plénières seront l\\'occasion de faire un point, avec des intervenants internationaux, sur la mise en uvre de Rio, et sur la préparation de Johannesburg.Et lors de la table-ronde de clôture, je présenterai l\\'état d\\'avancement de cette stratégie française de développement durable proposée par le gouvernement. Cette stratégie est une commande faite à tous les Etats, et sera présentée à Johannesburg. La concertation continuera après Toulouse, mais nous tenons à présenter à Toulouse le fruit de nos travaux.Enfin, je vous indique que les Assises seront placées sous le parrainage de Jean-Louis Etienne, le célèbre explorateur polaire, dont \" l\\'opération Banquise \" est co-financée par le MATE et par le Conseil régional Midi-Pyrénées.J\\'insiste sur l\\'importance que revêt ce moment de débat, de partage d\\'expériences, dans la perspective de la préparation du sommet du développement durable. C\\'est à travers les débats sur le développement durable que s\\'exprime la recherche de nouvelles régulations face au mouvement de mondialisation. Les équilibres entre les critères de justice et de solidarité sociale, de gestion raisonnée des ressources naturelles et de l\\'environnement, des préférences collectives en matière de santé et d\\'éducation sont au cur des controverses sur la mondialisation. La place des acteurs non institutionnels, le rôle des collectivités locales, le besoin de règles encadrant l\\'intégration des économies et des sociétés s\\'affirme de façon croissante et ces sujets devront être au cur du débat à Johannesburg.Les Assises de Toulouse seront un moment important de la préparation de cet événement majeur pour l\\'avenir de notre planète. C\\'est pourquoi j\\'ai le plaisir de vous y convier. Je vous remercie. ('),\n",
              " Row(Texte=\"Madame la Présidente, Mesdames et Messieurs les vice-présidents et conseillers, Monsieur le rapporteur général, Je suis heureux d'être ici, rue de l'Échelle, afin de saluer votre Conseil, autorité indépendante qui veille au respect des règles de concurrence et contribue ainsi à ce que le marché fonctionne dans l'intérêt collectif. L'installation du Conseil de la concurrence dans une formation renouvelée après le remplacement d'une partie de ses membres et de son rapporteur général intervenu dans les mois qui viennent de s'écouler est pour moi un acte significatif et d'importance. Il l'est pour 4 raisons : 1 -Tout d'abord parce que je suis convaincu du rôle que doit jouer la concurrence pour favoriser la croissance, l'innovation, l'emploi. En effet, notre économie, pour être développée, compétitive et se moderniser dans le cadre exigeant de la mondialisation, et à l'échelle européenne d'un marché plus intégré avec la mise place de l'euro, doit utiliser les potentialités que recèle la concurrence. La concurrence, si elle ne garantit pas à elle seule une croissance équilibrée, durable et riche en emplois, en est néanmoins un élément nécessaire. L'ouverture du marché à la concurrence permet d'améliorer l'allocation des ressources et de stimuler l'innovation qui va permettre l'introduction sur le marché de produits et services nouveaux. Ceux qui, dans le passé, ont eu le sentiment que des formes de protection ou de monopole pouvaient faciliter le développement, doivent reconnaître aujourd'hui que, mis à part quelques domaines très particuliers, c'est par une attitude offensive face à la concurrence et non en cherchant à s'en protéger, c'est en prenant des risques, que les entreprises peuvent se développer. L'intérêt général exige, j'en suis convaincu, une intervention pour corriger certains excès ou défaillances des marchés et empêcher que, par des ententes ou des abus de domination, des entreprises s'attribuent un avantage et constituent des rentes au détriment d'autres entreprises et des consommateurs. Les autorités publiques doivent établir les règles du jeu qui s'imposent aux opérateurs privés et déterminer la place de la concurrence dans la régulation économique des différents secteurs, définir les conditions dans lesquelles elle jouera afin de favoriser la croissance, la compétitivité, l'innovation et l'emploi mais aussi de concourir aux missions de service public et de préserver la solidarité. Tel est le rôle d'une véritable politique de la concurrence, qui veille au respect de comportements loyaux, au maintien de structures compatibles avec l'effectivité de la concurrence et à la liberté d'accès des nouveaux entrants sur le marché. Je sais que votre Conseil participe activement au fonctionnement du dispositif français de régulation de la concurrence en lui donnant toute sa portée. 2 -Cette installation de votre Conseil est également l'occasion pour moi de rappeler que le Conseil de la concurrence constitue une autorité prestigieuse, qui bénéficie désormais d'une forte reconnaissance auprès des entreprises. Je tiens à en remercier tout particulièrement ceux d'entre vous qui siègent depuis des années au Conseil et ont permis ce résultat. Votre Conseil a plusieurs missions importantes pour le bon fonctionnement de l'économie. Tout d'abord, le Conseil de la concurrence veille au respect des règles du droit de la concurrence et sanctionne les comportements fautifs des entreprises en France. Ce volet du droit figure désormais parmi ceux qui comptent pour les opérateurs économiques. Ceci génère pour eux des obligations mais ils se le sont également approprié et n'hésitent pas à l'invoquer à leur avantage comme un élément de leur stratégie de pénétration des marchés ou de défense de leurs intérêts menacés par des pratiques anticoncurrentielles. Ceci se traduit par l'accroissement très fort des saisines contentieuses (107 saisines contentieuses en 1998 contre 81 en 1997) émanant de plus en plus largement des entreprises et organisations professionnelles (72 saisines en 1998 contre 49 en 1997). Bien sûr ceci a un revers, puisque, malgré une activité dense et soutenue de votre Conseil, qui a rendu 109 décisions et 24 avis en 1998, le stock de dossiers en instance demeure important (327 en 1998). Ce succès de votre Conseil se traduit aussi dans l'accroissement de son activité consultative. Il a eu à ce prononcer dans les derniers mois sur des opérations de concentration importantes. Les demandes d'avis qui lui sont adressées portent également sur le fonctionnement de secteurs de l'économie comme celui de l'électricité qui s'ouvre à la concurrence, des télécommunications qui poursuit sa mutation ou de l'assurance ou encore sur des questions de concurrence plus ponctuelles, mais non moins importantes, dans des secteurs variés. Christian Pierret et moi-même venons tout juste de vous adresser une demande d'avis sur le secteur du gaz. Votre Conseil rendra prochainement un avis sur le document de consultation sur la réforme du code des marchés publics, dont je vous remercie par avance, car la pertinence de vos remarques permettra d'éclairer fort utilement l'action du gouvernement sur ce sujet important. Croyez bien que de mon côté je veille à ce que le gouvernement saisisse votre Conseil pour avis à chaque fois que cela est nécessaire. Outre les demandes d'origine gouvernementale, d'autres demandes d'avis émanent d'organisations professionnelles mais aussi d'autorités de régulation sectorielles comme l'agence de régulation des télécommunications et plus récemment du Conseil d'État. 3 - Le 3e point sur lequel je souhaite insister est le rôle nouveau qui se dessine peu à peu pour votre Conseil dans la régulation de nouveaux secteurs, celui de garant de l'unicité du droit de la concurrence. Le Conseil de la concurrence joue un rôle essentiel dans l'application du droit de la concurrence dans les nouveaux secteurs qui s'ouvrent à la concurrence comme les industries de réseau. Il est important à cet égard, dans un souci de cohérence et d'efficacité de la régulation, qu'il conserve une compétence de droit commun en matière de concurrence alors que de nouvelles autorités se voient confier des missions de régulation des marchés dans ces secteurs. L'efficacité de la régulation concurrentielle et la préservation de l'unicité des règles repose sur la bonne articulation entre l'activité des autorités sectorielles et celle de votre Conseil. Tous les intervenants s'accordent à reconnaître que les relations entre votre Conseil et l'Agence de Régulation des Télécommunications sont très satisfaisantes et je sais que vous saurez organiser les mêmes relations avec la Commission de Régulation de l'Électricité. La presse s'est fait l'écho de la décision toute récente du Conseil concernant l'offre d'accès rapide à Internet par l'ADSL. Je ne commenterai pas bien sûr cette décision mais je suis personnellement convaincu que nous avons déjà trop tardé dans ce domaine. La décision du Conseil de la Concurrence peut avoir pour effet de retarder de quelques semaines la mise à disposition de cette offre nouvelle. Ce n'est pas tragique bien sûr mais je regrette tout ce qui peut retarder la mise en place de cette technologie, essentielle pour le développement d'Internet. Et l'échelle de temps en ce domaine ne se mesure pas en années mais en mois. J'insisterai également sur l'idée que le droit français, comme d'ailleurs le droit communautaire, de la concurrence institue une régulation de droit commun, qui s'applique à tous les secteurs de l'économie sans exception sectorielle, même si certaines sont parfois revendiquées. La neutralité économique du droit exige que les méthodes d'analyse, les principes mis en oeuvre, les sanctions encourues ou la nature des obligations à supporter soient homogènes d'un secteur à l'autre. Ce droit général autorise bien entendu une souplesse d'application pour prendre en compte des particularités réglementaires et économiques des divers secteurs et marchés. Cette approche semble la bonne aussi bien pour le contrôle des comportements anticoncurrentiels que pour le contrôle plus structurel des concentrations. Tel est le sens des positions que j'ai défendues dans le domaine de l'audiovisuel, pour lequel le projet de loi en discussion permet à votre Conseil de retrouver sa pleine compétence en matière d'application du contrôle des concentrations, ainsi que par une meilleure articulation avec le CSA. 4 -Cette installation est enfin l'occasion pour moi de vous exprimer ma confiance dans la capacité de votre Conseil à optimiser son mode de fonctionnement pour faire face à son succès et à ses nouvelles responsabilités L'application plus effective du droit de la concurrence repose sur la rapidité d'intervention et de traitement des affaires. J'ai incité mes services à travailler en ce sens en recherchant une augmentation de la rapidité de leurs interventions et une diversification des suites réservées à leurs enquêtes afin de ne pas encombrer votre Conseil de saisines pour lesquelles d'autres voies permettent de rétablir le bon ordre concurrentiel. L'action de votre Conseil est bien entendu essentielle pour donner toute sa portée à cette volonté de renforcement de l'effectivité du droit de la concurrence. Sa nouvelle composition, ainsi que les moyens renforcés qui lui sont d'ores et déjà acquis lui offrent les atouts pour y parvenir. En premier lieu, le Conseil de la concurrence a, depuis quelques mois, renforcé l'effectivité du droit de la concurrence en prononçant à plusieurs reprises des mesures conservatoires. Ceci correspond à un souhait des opérateurs économiques, qui accompagnent de plus en plus souvent leur saisine au fond d'une demande de mesures conservatoires (28 demandes formulées en 1998 contre 12 en 1997). C'est aussi un moyen d'intervenir en urgence pour réguler un marché et prévenir ou faire cesser des pratiques susceptibles d'être condamnées comme anticoncurrentielles. Votre Conseil est conduit à renforcer sa capacité technique notamment pour assurer la régulation des industries de réseau et du secteur de l'audiovisuel qui conduisent à traiter de litiges complexes et techniques. Par l'arrivée de nouveaux membres, professionnels ou économiste, et de rapporteurs qui ont une sensibilité affirmée aux problèmes posés par les secteurs des industries de réseau ou de l'audiovisuel dans le jeu de la concurrence, votre Conseil a les moyens d'asseoir encore davantage à l'avenir son rôle pivot dans la régulation de la concurrence sur ces marchés. Cette orientation pourra être poursuivie à la faveur des remplacements de rapporteurs pour favoriser des recrutements qui viseraient prioritairement à en diversifier le profil et à compléter la connaissance de ces secteurs au sein du Conseil. Surtout, un renforcement des mesures d'organisation interne du Conseil et une adaptation de ses procédures s'avèrent nécessaires. Une augmentation du nombre des rapporteurs du Conseil a été décidée et s'est concrétisée ces dernières années. Afin de contribuer à la productivité du Conseil par un renforcement de l'encadrement, j'ai accepté la création d'un poste d'un rapporteur général adjoint en 1999. S'agissant des questions de procédure, et de respect des droits de la défense, elle sont également un élément important de l'évolution qui se dessine. Je pense notamment à l'évolution jurisprudentielle en ce qui concerne la présence du rapporteur et du rapporteur général au délibéré, si la Cour de cassation confirme un arrêt récent de la Cour d'appel de Paris. La fin de leur participation suppose en effet un investissement supplémentaire et approfondi des membres du Conseil dans le contenu des dossiers. De même, le souci de protéger le secret des affaires lors des auditions et dans les rapports, tant sur des affaires de pratiques anticoncurrentielles que lors des avis sur les questions de concentration est une préoccupation forte. Enfin le projet de réforme du règlement 17/62 présenté par la Commission européenne, qui s'inspire du système français en remplaçant le système actuel de contrôle communautaire a priori et centralisé des pratiques anticoncurrentielles par un contrôle a posteriori et largement décentralisé dans les États membres, est porteur de perspectives nouvelles pour votre Conseil, qui se verra investi de nouvelles compétences si cette réforme est adoptée dans les années à venir. Il conviendra alors de réexaminer ses moyens pour faire face à ces tâches supplémentaires. Afin de faciliter l'accès rapide à l'information à la fois pour les agents du ministère mais surtout pour les utilisateurs que sont les entreprises, les avocats et les consommateurs, j'ai souhaité la mise en ligne du BOCCRF sur le site Internet du ministère. Voilà Madame la Présidente, Mesdames et Messieurs les quelques réflexions que je souhaitais vous présenter, animé du seul souci d'une affirmation toujours plus forte du droit de la concurrence et du rôle dévolu au Conseil de la concurrence dans son application. Je me réjouis de l'installation de ce nouveau Conseil, qui s'appuie sur l'expérience des anciens membres, qui s'est ouvert à de nouvelles compétences, qui s'est très fortement féminisé. J'émets le voeu que :le collège renouvelé du Conseil de la concurrence que vous constituez désormais déploie très rapidement une activité soutenue et de qualité à la hauteur des attentes qui, vous le mesurez, sont très fortes. qu'à la faveur de l'expression de courants de pensée divers en matière économique et juridique, il s'emploie à faire encore progresser le droit de la concurrence et son effectivité en France en abordant de nouveaux secteurs économiques ou de nouveaux thèmes. Je vous souhaite donc un excellent travail. (\")]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo5_Hml9DNwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9d829f0-0d64-470f-af9c-1d73a3dc1544"
      },
      "source": [
        "text='''\n",
        "Mesdames, Messieurs,Je vous ai invité à ce point presse pour vous présenter les Assises nationales du développement durable, que nous organisons, conjointement avec la région Midi-Pyrénées, dont Mme Marie-Françoise Mendez, ici présente, est vice-présidente.Nous nous étions déjà réunis, avec M. le Président Martin Malvy, le 15 janvier dernier, à la signature de la convention entre le MATE et le Conseil Régional Midi-Pyrénées. Aujourd\\'hui, à 10 jours de la tenue de ces Assises, je tenais à vous en rappeler l\\'importance, et à vous en présenter les enjeux.Le sommet mondial du développement durable de Johannesburg aura lieu à la fin du mois d\\'août prochain, c\\'est-à-dire très bientôt.La France et l\\'Europe ont un rôle essentiel à jouer dans ce sommet, d\\'autant, vous l\\'avez vu, que M. le Président Bush menace de ne pas s\\'y rendre lui-même, malgré les exhortations de nombreuses associations.Vous connaissez le contexte électoral particulier dans lequel nous nous trouvons aujourd\\'hui. Il est difficile, dans ces conditions, de se projeter dans l\\'après- mois de mai/juin. Pourtant , c\\'est notre rôle de le faire. Les Assises Nationales du développement durable de Toulouse, qui se tiendront les 11 et 12 mars prochains, seront ainsi l\\'occasion, en France, avant ces échéances électorales internes, d\\'ouvrir un large dialogue sur la préparation du sommet de Johannesburg, et sur le bilan de ce qui a été réalisé dans notre pays depuis la conférence de Rio en 1992.Le concept de développement durable a été popularisé par le rapport \" Brundtland \", rapport de la Commission Mondiale sur l\\'Environnement et le Développement, en 1987. C\\'est dans ce rapport qui a proposé la définition la plus communément admise du développement durable : \" un développement qui réponde aux besoins du présent sans compromettre la capacité des générations futures à répondre aux leurs \" Vous le savez, le Sommet de la Terre, a constitué une étape décisive dans l\\'engagement des pays en faveur du développement durable et dans l\\'expression des finalités et principes fondateurs de ce concept. Elle a mis en valeur l\\'idée selon laquelle \" le monde se localise en même temps qu\\'il se mondialise \". Les espoirs de Rio, vous le savez aussi, n\\'ont pas encore été concrétisés : les modes de production et de consommation ont peu changé, les écarts entre le Nord et le Sud se sont aggravés.Vous connaissez les principes fondateurs du développement durable : la prise en compte, en amont de toute politiques publique et à chaque étape de leur mise en oeuvre, des trois piliers que sont le développement économique, la protection de l\\'environnement, et le bien être social. Cette imbrication suppose de sortir de l\\'idéologie de la croissance du PIB comme seul objectif des politiques de développement. J\\'insiste pour ma part sur le fait que le développement durable envisage la personne humaine dans sa globalité. En ce sens, le souci de l\\'éducation, de la formation tout au long de la vie, de la diversité culturelle et de la protection de la liberté nécessaire à toute création artistique, à toute pensée, font partie du développement durable.Les principes affirmés à Rio irriguent notre action quotidienne, au sein de ce Ministère, mais aussi au sein de toutes les collectivités locales :- le principe d\\'intégration de la protection de l\\'environnement comme partie intégrante du processus de développement ; - le principe de responsabilité et de solidarité internationale ;- le principe de participation et de nouvelle gouvernance ;Les 171 gouvernements présents à Rio ont aussi adopté l\\'Agenda 21 (ou Action 21). Il constitue un plan global d\\'action qui doit être mis en uvre par les gouvernements, les institutions du développement, les organismes des Nations Unies et les secteurs indépendants.Ses 40 chapitres font émerger : - les dimensions économiques et sociales ;- la conservation et la préservation des ressources aux fins de développement ;- la participation de la société civile à l\\'élaboration et la mise en oeuvre d\\'actions s\\'appuyant sur l\\'expression des besoins de la société civile ; - la mise en oeuvre de moyens transversaux à toutes les échelles de territoires. Le chapitre 28 recommande ainsi que les collectivités locales mettent en place un Agenda 21 local, traductionterritorialisée de l\\'Agenda 21.Depuis Rio, une étape majeure a été franchie à Kyoto, en 1997, et Johannesburg sera la prochaine. Les enjeux de Johannesburg sont donc fondamentaux : Le Premier Ministre l\\'a rappelé dans son discours de Lyon, en soulignant notamment la nécessité d\\'une OME, de la ratification du Protocole de Kyoto.Cependant, nous avons quelques inquiétudes car le contexte international n\\'est pas favorable : le programme d\\'action de George Bush pour le changement climatique est inacceptable, la conférence de Carthagène a été décevante, celle de Monterrey ne laisse pas d\\'être inquiétanteDans ce contexte, il importe plus que jamais de se mobiliser pour que le Sommet du Développement Durable soit un succès qui redonne un nouveau souffle au concept, en insistant sur la nécessaire intégration des préoccupations économiques, sociales et environnementales.\n",
        "'''\n",
        "result = light_model.annotate(text)\n",
        "\n",
        "result['class']"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GscFqU23bbwJ",
        "colab_type": "text"
      },
      "source": [
        "``` bert_multi_cased ``` est une base de pretrained word embeddings. Elle contient plusieurs langues. \n",
        "\n",
        "Les problèmes avec cette méthode est :\n",
        "- beaucoup de calcul : Le modèle est deep et le texte est longue pour chaque discours.\n",
        "- information sparse ( multi-lingue) : Nous voulons entrainer le modèle avec CamemBERT qui est dédiée pour la langue française, pourtant cette base n'est pas disponible sur sparknlp pour l'instant. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNok-RN0Ri8A",
        "colab_type": "text"
      },
      "source": [
        "### Conclusion : \n",
        "Les méthodes de machine learning permettent d'avoir des scores satisfaisants avec peu de temps d'éxecution. Avec le tuning des hyperparamètres, nous faisons du multi-processing avec `pyspark`.  \n",
        "Le problème avec les modèles deep learning sur spark quand on traite avec le CPU, nous ne pouvons pas faire mieux que quand on travaille sur le GPU. Et les resultats est moins satisfaisant avec le temps et la capacité de calcul limités.\n",
        "\n"
      ]
    }
  ]
}